name: scrape-and-publish

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */6 * * *"  # 6 saatte bir

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements_scrape.txt

      - name: Run scrapers
        env:
          CHROME_BIN: /usr/bin/chromium-browser
          CHROMEDRIVER_PATH: /usr/bin/chromedriver
        run: |
          python scripts/run_scrapers.py

      - name: Commit outputs
        run: |
          git config user.name "scrape-bot"
          git config user.email "scrape-bot@users.noreply.github.com"
          git add data/*.csv
          git commit -m "Update scraped data [skip ci]" || echo "No changes"
          git push

